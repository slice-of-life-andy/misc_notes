= Basic Concept

== NRT

 a slight latency(normally one second)


== Cluster

  A cluster is a collection of one or more nodes (servers) that together holds your entire data and provides federated indexing and search capabilities across all nodes.
  A cluster is identified by a unique name which by default is "elasticsearch". 
  uses multicast network discovery by default to find other nodes.  
 
== Node

 A node is a single server that is part of your cluster, stores your data, and participates in the cluster’s indexing and search capabilities. Just like a cluster, a node is identified by a name which by default is a random Marvel character name that is assigned to the node at startup. You can define any node name you want if you do not want the default.

== Index

 An index is a collection of documents that have somewhat similar characteristics.
 In a single cluster, you can define as many indexes as you want.

== Type
 
 Within an index, you can define one or more types. A type is a logical category/partition of your index whose semantics is completely up to you. 

== Document

 A document is a basic unit of information that can be indexed. 


== Shards
 
 subdivide your index into multiple pieces called shards.When you create an index, you can simply define the number of shards that you want. Each shard is in itself a fully-functional and independent "index" that can be hosted on any node in the cluster.

== Replicas

 Elasticsearch allows you to make one or more copies of your index’s shards into what are called replica shards, or replicas for short.


Replication is important for two primary reasons:

* It provides high availability in case a shard/node fails. For this reason, it is important to note that a replica shard is never allocated on the same node as the original/primary shard that it was copied from.
* It allows you to scale out your search volume/throughput since searches can be executed on all replicas in parallel.


To summarize, each index can be split into multiple shards. An index can also be replicated zero (meaning no replicas) or more times. Once replicated, each index will have primary shards (the original shards that were replicated from) and replica shards (the copies of the primary shards). The number of shards and replicas can be defined per index at the time the index is created. After the index is created, you may change the number of replicas dynamically anytime but you cannot change the number shards after-the-fact.

By default, each index in Elasticsearch is allocated 5 primary shards and 1 replica which means that if you have at least two nodes in your cluster, your index will have 5 primary shards and another 5 replica shards (1 complete replica) for a total of 10 shards per index.


== Installation

 ./elasticsearch --cluster.name my_cluster_name --node.name my_node_name

== Exploring Your Cluster

=== The REST API

Among the few things that can be done with the API are as follows:

* Check your cluster, node, and index health, status, and statistics
* Administer your cluster, node, and index data and metadata
* Perform CRUD (Create, Read, Update, and Delete) and search operations against your indexes
* Execute advanced search operations such as paging, sorting, filtering, scripting, faceting, aggregations, and many others



=== Cluster Health

 curl 'localhost:9200/_cat/health?v'

 health status: green, yellow, or red

 curl 'localhost:9200/_cat/nodes?v'

=== List All Indices

 curl 'localhost:9200/_cat/indices?v'

=== Create an Index

 curl -XPUT 'localhost:9200/customer?pretty'
 curl 'localhost:9200/_cat/indices?v'

=== Index and Query a Document

 Let’s index a simple customer document into the customer index, "external" type, with an ID of 1 as follows:

[source,shell]
----
andy@it:~/james.ahamojo.cn$ curl -XPUT 'localhost:9200/customer/external/1?pretty' -d '{"name":"John Doe"}'
{
  "_index" : "customer",
  "_type" : "external",
  "_id" : "1",
  "_version" : 1,
  "created" : true
}
----

[source,shell]
----
andy@it:~/james.ahamojo.cn$ curl -XGET 'localhost:9200/customer/external/1?pretty'
{
  "_index" : "customer",
  "_type" : "external",
  "_id" : "1",
  "_version" : 1,
  "found" : true,
  "_source":{"name":"John Doe"}
}

----


=== Delete an Index

 curl -XDELETE 'localhost:9200/customer?pretty'


=== access pattern summarized 

 curl -X<REST Verb> <Node>:<Port>/<Index>/<Type>/<ID>

== Modifying Your Data

===  indexing/replace document

 same with index a document

 the document id is optional   
 curl -XPOST 'localhost:9200/customer/external?pretty' -d '{"name":"John Doe"}'

=== Updating Documents

 curl -XPOST 'localhost:9200/customer/external/1/_update?pretty' -d '{"doc": { "name": "James Doe" }}'

 curl -XPOST 'localhost:9200/customer/external/1/_update?pretty' -d '{"doc": { "age": "20" }}'

 curl -XPOST 'localhost:9200/customer/external/1/_update?pretty' -d '{"script" : "ctx._source.age += 5"}'

 In the above example, ctx._source refers to the current source document that is about to be updated.

 Note that as of this writing, updates can only be performed on a single document at a time. In the future, Elasticsearch might provide the ability to update multiple documents given a query condition (like an SQL UPDATE-WHERE statement).
 
 Error handing 
 
 ElasticsearchIllegalArgumentException[failed to execute script]; nested: ScriptException[scripts of type [inline], operation [update] and lang [groovy] are disabled];

 add following lines in the conf/elasticsearch.yml
 script.inline: on
 script.indexed: on  

=== Deleting Documents

 curl -XDELETE 'localhost:9200/customer/external/2?pretty'
 
 curl -XDELETE 'localhost:9200/customer/external/_query?pretty' -d '{"query": { "match": { "name": "John" } }}'


=== Batch Processing

 curl -XPOST 'localhost:9200/customer/external/_bulk?pretty' -d '{"index":{"_id":"1"}}{"name": "John Doe" }{"index":{"_id":"2"}}{"name": "Jane Doe" }'
 
 curl -XPOST 'localhost:9200/customer/external/_bulk?pretty' -d '{"update":{"_id":"1"}}{"doc": { "name": "John Doe becomes Jane Doe" } }{"delete":{"_id":"2"}}'


== Exploring Your Data
 
=== Loading the Sample Dataset
 
 curl -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.json
 curl 'localhost:9200/_cat/indices?v'  

=== The Search API 

 curl 'localhost:9200/bank/_search?q=*&pretty' 
 curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query": { "match_all": {} }}'


=== Introducing the Query Language

 curl -XPOST 'localhost:9200/bank/_search?pretty' -d '
{
  "query": { "match_all": {} },
  "from": 10,
  "size": 10
}'

The from parameter (0-based) specifies which document index to start from and the size parameter specifies how many documents to return starting at the from parameter. This feature is useful when implementing paging of search results.Note that if from is not specified, it defaults to 0.

curl -XPOST 'localhost:9200/bank/_search?pretty' -d '
{
  "query": { "match_all": {} },
  "sort": { "balance": { "order": "desc" } }
}'


=== Executing Searches

This example shows how to return two fields, account_number and balance (inside of _source), from the search:

curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query": { "match_all": {} },"_source": ["account_number", "balance"]}'

query account_number =20

curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query": { "match": { "account_number": 20 } }}'

This example returns all accounts containing the term "mill" in the address:
curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query":{"match":{"address":"mill"}}}'

This example returns all accounts containing the term "mill" or "lane" in the address:
curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query":{"match":{"address":"mill lane"}}}'

This example is a variant of match (match_phrase) that returns all accounts containing the phrase "mill lane" in the address:
curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query":{"match_phrase":{"address":"mill lane"}}}'


bool(ean) query

This example composes two match queries and returns all accounts containing "mill" and "lane" in the address:
curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query": {"bool": {"must": [{ "match": { "address": "mill" } },{ "match": { "address": "lane" } }]}}}'
in the above example, the bool must clause specifies all the queries that must be true for a document to be considered a match.

In contrast, this example composes two match queries and returns all accounts containing "mill" or "lane" in the address:
curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query":{"bool":{"should":[{"match":{"address":"mill"}},{"match":{"address":"lane"}}]}}}'

This example composes two match queries and returns all accounts that contain neither "mill" nor "lane" in the address:
curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query":{"bool":{"must_not":[{"match":{"address":"mill"}},{"match":{"address":"lane"}}]}}}'
In the above example, the bool must_not clause specifies a list of queries none of which must be true for a document to be considered a match.

We can combine must, should, and must_not clauses simultaneously inside a bool query. Furthermore, we can compose bool queries inside any of these bool clauses to mimic any complex multi-level boolean logic.

This example returns all accounts of anybody who is 40 years old but don’t live in ID(aho):

curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query":{"bool":{"must":[{"match":{"age":"40"}}],"must_not":[{"match":{"state":"ID"}}]}}}'

=== Executing Filters 


In the previous section, we skipped over a little detail called the document score (_score field in the search results). The score is a numeric value that is a relative measure of how well the document matches the search query that we specified. The higher the score, the more relevant the document is, the lower the score, the less relevant the document is.

All queries in Elasticsearch trigger computation of the relevance scores. In cases where we do not need the relevance scores, Elasticsearch provides another query capability in the form of filters. Filters are similar in concept to queries except that they are optimized for much faster execution speeds for two primary reasons:

Filters do not score so they are faster to execute than queries

Filters can be cached in memory allowing repeated search executions to be significantly faster than queries

To understand filters, let’s first introduce the filtered query, which allows you to combine a query (like match_all, match, bool, etc.) together with a filter. As an example, let’s introduce the range filter, which allows us to filter documents by a range of values. This is generally used for numeric or date filtering.

This example uses a filtered query to return all accounts with balances between 20000 and 30000, inclusive. In other words, we want to find accounts with a balance that is greater than or equal to 20000 and less than or equal to 30000.

curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"query":{"filtered":{"query":{"match_all":{}},"filter":{"range":{"balance":{"gte":20000,"lte":30000}}}}}}'



=== Executing Aggregations

Aggregations provide the ability to group and extract statistics from your data. The easiest way to think about aggregations is by roughly equating it to the SQL GROUP BY and the SQL aggregate functions. In Elasticsearch, you have the ability to execute searches returning hits and at the same time return aggregated results separate from the hits all in one response. This is very powerful and efficient in the sense that you can run queries and multiple aggregations and get the results back of both (or either) operations in one shot avoiding network roundtrips using a concise and simplified API.

To start with, this example groups all the accounts by state, and then returns the top 10 (default) states sorted by count descending (also default):

curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"size":0,"aggs":{"group_by_state":{"terms":{"field":"state"}}}}'

in the sql 
SELECT COUNT(*) from bank GROUP BY state ORDER BY COUNT(*) DESC


Note that we set size=0 to not show search hits because we only want to see the aggregation results in the response.

Building on the previous aggregation, this example calculates the average account balance by state (again only for the top 10 states sorted by count in descending order):
curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"size":0,"aggs":{"group_by_state":{"terms":{"field":"state"},"aggs":{"average_balance":{"avg":{"field":"balance"}}}}}}'

Building on the previous aggregation, let’s now sort on the average balance in descending order:

 curl -XPOST 'localhost:9200/bank/_search?pretty' -d '{"size":0,"aggs":{"group_by_state":{"terms":{"field":"state","order":{"average_balance":"desc"}},"aggs":{"average_balance":{"avg":{"field":"balance"}}}}}}'


This example demonstrates how we can group by age brackets (ages 20-29, 30-39, and 40-49), then by gender, and then finally get the average account balance, per age bracket, per gender:

[source,json]
----
curl -XPOST 'localhost:9200/bank/_search?pretty' -d '
{
  "size": 0,
  "aggs": {
    "group_by_age": {
      "range": {
        "field": "age",
        "ranges": [
          {
            "from": 20,
            "to": 30
          },
          {
            "from": 30,
            "to": 40
          },
          {
            "from": 40,
            "to": 50
          }
        ]
      },
      "aggs": {
        "group_by_gender": {
          "terms": {
            "field": "gender"
          },
          "aggs": {
            "average_balance": {
              "avg": {
                "field": "balance"
              }
            }
          }
        }
      }
    }
  }
}'

----
