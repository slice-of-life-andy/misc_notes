== Installation 

 start background
 bin/elasticsearch -d

== Configuration

=== Environment Variables

JAVA_OPTS
ES_JAVA_OPTS
ES_HEAP_SIZE
ES_MIN_MEM(256m)
ES_MAX_MEM(1g)


=== System Configuration

File Descriptors

Make sure to increase the number of open files descriptors on the machine (or for the user running elasticsearch). Setting it to 32k or even 64k is recommended.

In order to test how many open files the process can open, start it with -Des.max-open-files set to true. This will print the number of open files the process can open on startup.

Alternatively, you can retrieve the max_file_descriptors for each node using the Nodes Info API, with:
curl localhost:9200/_nodes/process?pretty



=== Virtual memory
 
Elasticsearch uses a hybrid mmapfs / niofs directory by default to store its indices. The default operating system limits on mmap counts is likely to be too low, which may result in out of memory exceptions. On Linux, you can increase the limits by running the following command as root:

sysctl -w vm.max_map_count=262144
To set this value permanently, update the vm.max_map_count setting in /etc/sysctl.conf.

Note
If you installed Elasticsearch using a package (.deb, .rpm) this setting will be changed automatically. To verify, run sysctl vm.max_map_count.


=== Memory Settings

Most operating systems try to use as much memory as possible for file system caches and eagerly swap out unused application memory, possibly resulting in the elasticsearch process being swapped. Swapping is very bad for performance and for node stability, so it should be avoided at all costs.

There are three options:
* Disable swap
* Configure swappiness
* mlockall

=== Elasticsearch Settings

=== Index Settingsedit

=== Logging


== upgrade

shutdown a single node 
curl -XPOST 'http://localhost:9200/_cluster/nodes/_local/_shutdown'


Stop all Elasticsearch services on all nodes in the cluster.
curl -XPOST 'http://localhost:9200/_shutdown'



run in docker with root 
bin/elasticsearch -Des.insecure.allow.root=true
